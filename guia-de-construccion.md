# Guía Estratégica de Desarrollo por Fases para Mateatletas (Monorepo Next.js/NestJS)

Mateatletas es una plataforma educativa que se construirá mediante un enfoque progresivo por fases, utilizando un monorepo modular que integra Next.js (frontend) y NestJS (backend) junto con Prisma y PostgreSQL. El objetivo es lograr una arquitectura impecable, escalable, testeada y documentada, facilitando además la colaboración entre desarrolladores (y agentes de IA) sin interferencias. A continuación se detalla la metodología dividida en fases, junto con estrategias de testing, reutilización de componentes y documentación viva.

## Fase 0: Setup del entorno y estructura del monorepo

**Objetivo técnico:** Establecer los cimientos del proyecto en un monorepo, con una estructura clara que contenga las aplicaciones de frontend y backend, asegurando configuraciones iniciales consistentes. Se busca un esqueleto de proyecto limpio, funcional y listo para escalar.

### Artefactos esperados:

- **Estructura base del monorepo** (p. ej., directorio raíz con package.json y carpetas /apps o similares). Dentro, un proyecto Next.js (ej. `apps/web`) y un proyecto NestJS (ej. `apps/api`), configurados para trabajar en conjunto.
- **Configuración de TypeScript unificada** (tsconfig base y específicos para front/back) para permitir compartir tipos.
- **Configuración de gestor de paquetes monorepo** (por ejemplo Nx o PNPM Workspaces), scripts de build/start para frontend y backend, y posiblemente un Turborepo para orquestar tareas comunes.
- **Archivos de configuración básicos:** ESLint y Prettier para mantener estilo de código consistente, configuración de env (variables de entorno para dev y producción, incluyendo credenciales de base de datos, etc.).
- **Setup inicial de Prisma:** archivo schema.prisma vacío o con un par de modelos de ejemplo y conexión a PostgreSQL configurada (cadena de conexión en .env).
- **Integración de control de versiones y CI/CD inicial:** repositorio Git con un pipeline mínimo (por ejemplo, GitHub Actions) que instale dependencias y ejecute un build de prueba de las apps.

### Dependencias:

No aplica (es la fase inicial). Preparar el entorno es previo a cualquier otra fase, sin dependencias más que tener las herramientas (Node.js, pnpm/npm, Nest CLI, etc.) instaladas.

### Herramientas y librerías recomendadas:

- **NestJS CLI** para crear el proyecto backend (`nest new`) y Create Next App (o equivalente) para iniciar el frontend. Esto agiliza la creación de la estructura básica.
- **Nx o Turborepo** para manejar el monorepo eficientemente, permitiendo comandos unificados y caching de builds.
- **TypeScript** (configurado en modo estricto) en todo el repositorio, para garantizar tipado consistente de extremo a extremo.
- **ESLint + Prettier** para asegurar calidad de código desde el día 0.
- **Husky + lint-staged** (opcional) para configurar ganchos pre-commit que ejecuten formateo, linters y tests básicos, evitando introducir errores obvios sin frenar el flujo creativo.

### Criterios de validación y cierre de fase:

- **Monorepo estructurado:** se puede levantar el servidor NestJS (ejecutando `npm run start:api`) y la app Next.js (`npm run dev:web`) sin errores, cada uno sirviendo "Hello World" por separado.
- Las dependencias comunes funcionan en ambos proyectos (por ejemplo, TypeScript reconoce tipos compartidos, y se puede importar un tipo desde backend a frontend si así se define).
- El equipo (o agentes de IA) dispone de documentación inicial sobre cómo correr el proyecto, cómo está organizada la estructura de carpetas y cómo añadir nuevos módulos. Idealmente, un README inicial describe la arquitectura del monorepo y normas de desarrollo.
- **Entorno listo para siguiente fase:** linters pasando y base de datos PostgreSQL accesible (aunque sin datos reales aún). Un commit etiquetado como fase-0-complete cierra esta fase.

## Fase 1: Construcción de componentes UI atómicos

**Objetivo técnico:** Desarrollar la biblioteca de componentes UI atómicos reutilizables, junto con hooks utilitarios front-end, que servirán de base para construir funcionalidades más complejas. Se trata de implementar el diseño atómico desde átomos (botones, inputs, tarjetas) hasta moléculas y organismos (secciones completas), asegurando consistencia visual y posibilidad de reutilización en todo el frontend.

### Artefactos esperados:

- **Carpeta de componentes** (ej. `apps/web/src/components/`) que contiene componentes atómicos: botones, campos de texto, modal, spinner de carga, etc., siguiendo las guías de estilo de Mateatletas. Cada componente con su archivo .tsx, estilos (usando Tailwind CSS u otro sistema) y propiedades tipadas.
- **Configuración de Tailwind CSS** (o styled-components/Chakra UI según elección, pero Tailwind está sugerido) acorde al sistema de diseño: incluir en la configuración los colores, fuentes y estilos base definidos para Mateatletas. Por ejemplo, clases utilitarias o componentes estilizados con la "sombra chunky" característica de la marca.
- **Implementación de un sistema de diseño consistente:** por ejemplo, definir tokens de diseño (colores, fuentes) y aplicar principios de diseño consistente en los componentes. Artefacto: un archivo de temas o configuración de Tailwind que refleja estos tokens.
- **Hooks reutilizables en frontend** (ej. carpeta `hooks/`): por ejemplo, `useAuth()` para manejar estado de autenticación (inicialmente puede ser un stub), `useForm()` o hooks que encapsulan lógica repetitiva de formularios, etc.
- **Posiblemente integración de Storybook** u otro entorno de documentación viva de componentes, donde cada componente esté catalogado con ejemplos. Esto sirve tanto para ver los componentes aislados como para documentarlos de forma interactiva para el equipo.
- **Pruebas unitarias básicas de componentes:** por ejemplo, usar Vitest o Jest con React Testing Library para verificar que cada componente renderiza correctamente con diferentes props. Artefacto: archivos \*.spec.tsx junto a los componentes.
- **Documentación técnica inicial:** puede ser un manual de UI o simplemente MDX dentro de Storybook, explicando las propiedades y uso de cada componente. También un listado de convenciones (e.g., "todos los componentes deben recibir una prop className para estilos personalizados", etc.).

### Dependencias:

Requiere el entorno y proyecto Next.js funcionando (de Fase 0). No depende de lógica de backend ni de datos reales aún. La base de diseño puede provenir de guías de UX ya definidas, pero a nivel técnico esta fase se realiza en gran medida de forma independiente al backend.

### Herramientas y librerías recomendadas:

- **Tailwind CSS** para estilos utilitarios consistentes. Facilita aplicar el sistema de diseño sin escribir CSS desde cero, y asegura consistencia tipográfica y de spacing.
- **React Testing Library con Vitest/Jest** para testear componentes UI de forma declarativa (buscando texto, roles accesibles, etc.).
- **Storybook:** altamente recomendado para desarrollo asistido de componentes y como documentación viva de la UI. Permite que los diseñadores (o IA especializadas en front) validen componentes en aislamiento.
- **TanStack React Query:** aunque la integración real de datos vendrá después, se puede instalar desde ya para usar hooks de datos mock en Storybook o prepararse para el fetching declarativo de datos.
- **Zustand** u otro manejador de estado ligero para el cliente, si se prevé estado global (por ejemplo, un store de sesión de usuario). En esta fase podría crearse el esqueleto de ese store (con estado vacío o simulado) para que los componentes que dependan de estado global puedan usarse luego.

### Criterios de validación y cierre de fase:

- **Colección de componentes atómicos lista:** al menos todos los elementos básicos de la interfaz han sido creados y estilados según el diseño. Por ejemplo, botones con todos sus estados (hover, active), inputs con validación visual de error, etc., disponibles.
- **Reutilización verificada:** Los componentes deben demostrar que pueden integrarse entre sí sin conflictos (por ejemplo, un formulario compuesto de botones e inputs funciona correctamente en Storybook). No hay duplicación de estilos – se utilizan las utilidades de Tailwind o estilos centralizados en lugar de definiciones ad-hoc repetidas.
- **Pruebas de los componentes pasando:** si un componente tiene lógica (ej. un componente de modal que abre/cierra), hay tests que aseguran que esa lógica funciona. Los tests de snapshot o de render básico pasan sin regresiones visuales significativas.
- **Documentación de UI publicada o accesible:** los miembros del equipo pueden ver cada componente y saber cómo usarlo. Esta documentación viva (p. ej. Storybook) se considera parte del entregable.
- Esta fase se considera completa cuando el design system básico está implementado en código y hay confianza (mediante review y tests) de que los componentes pueden ser usados para construir pantallas completas en siguientes fases.

## Fase 2: Módulos funcionales (Auth, Clases, Usuarios, Pagos, Gamificación)

**Objetivo técnico:** Implementar las piezas funcionales principales de la plataforma, creando módulos de dominio tanto en el backend como en el frontend para cada segmento clave: Autenticación, Gestión de Usuarios/Clases, Pagos y Gamificación. En esta fase se construyen los endpoints básicos en el backend y las páginas o vistas correspondientes en el frontend, estableciendo la arquitectura modular por dominio en todo el sistema. Aunque algunas partes estarán inicialmente esqueléticas o con datos simulados, la idea es tener la estructura de cada módulo en funcionamiento. Cada módulo tendrá alta cohesión interna y bajo acoplamiento con los demás.

### Artefactos esperados:

- **Estructura modular en backend:** Dentro del proyecto NestJS, creación de módulos (carpetas en `src/modules`) para cada dominio: `auth`, `usuarios` (o tutores/estudiantes según modelo), `clases` (agenda académica), `pagos` y `gamificacion`. Cada módulo con sus subcomponentes típicos: controlador (_.controller.ts), servicio (_.service.ts), entidad o modelo (Prisma client se usará, pero podrían definirse clases de dominio si aplica) y DTOS para las operaciones principales. Artefacto específico: código NestJS que refleja estos módulos, por ejemplo AuthModule, ClasesModule, etc., registrados en AppModule del backend. Esta organización modular asegurará un proyecto ordenado y fácil de navegar.
- **Modelos de datos y Prisma:** Definición del esquema en schema.prisma para las entidades principales (usuarios, clases, inscripciones, pagos, logros, etc.), de acuerdo con el modelo de datos planeado. Tras definirlo, ejecutar migraciones para crear las tablas en PostgreSQL. Artefacto: un conjunto de migraciones SQL generadas por Prisma y el cliente TypeScript de Prisma actualizado (que provee tipos para consultas).
- **Servicios de dominio con lógica básica:** Por ejemplo, en AuthService métodos para registrar usuarios y hacer login (inicialmente quizá devolviendo tokens dummy), en ClasesService métodos para listar clases, en PagosService para crear órdenes de pago (inicialmente simuladas), etc. Aún sin todas las validaciones complejas, pero cubriendo el flujo "feliz" de cada caso de uso.
- **Endpoints iniciales:** Definir rutas HTTP en los controladores NestJS para cada funcionalidad principal, aunque algunas devuelvan datos simulados por ahora. Por ejemplo: POST /auth/register, POST /auth/login (retornando JWT), GET /api/clases (lista de clases dummy), POST /api/pagos (inicia pago), etc. Esto permite probar la integración más adelante.
- **Páginas y vistas en frontend para cada módulo:** En la aplicación Next.js, crear las páginas correspondientes (dentro de la estructura de rutas de Next, posiblemente bajo agrupaciones como (auth) para login/registro, dashboards para usuarios, etc.). Por ejemplo: página de login, página de registro, pantalla de listado de clases, pantalla de perfil de usuario, pantalla de compra/pago, pantalla de puntos/logros. De momento, estas páginas pueden usar datos falsos o mocks, pero utilizan los componentes de UI de la fase 1. Artefacto: código React/Next.js para cada página, usando los componentes atómicos donde corresponda (ej. la página de login usando componentes `<Input>` y `<Button>` del design system).
- **Stores o contexto de estado inicial:** Por ejemplo, un store global (usando Zustand o contexto de React) para auth donde se guarda el estado del usuario autenticado (token JWT, rol, etc.), con métodos para actualizarlo tras login/logout. Igualmente, quizás un contexto para carrito de pago o similar si aplica. Estos estados globales están listos aunque la lógica interna se complete después.
- **Integraciones básicas con servicios externos simuladas:** Por ejemplo, en el módulo de Pagos, incluir la estructura para integrar con Mercado Pago (con un service o provider específico), aunque inicialmente simule la creación de una preferencia de pago. Similar con cualquier otro servicio externo (p.ej. placeholder para integrar API de Jitsi o OpenAI si corresponde, aunque esas integraciones reales podrían postergarse).
- **Pruebas unitarias iniciales en backend:** Crear tests básicos con Jest para servicios críticos. Por ejemplo, probar que AuthService.hashPassword() funciona, o que GamificacionService.calcularNivel() retorna el nivel esperado dado ciertos puntos. Estas pruebas sientan la base para profundizar en Fase 4, pero algunas pueden hacerse ya.
- **Scripts y documentación:** Actualizar scripts de package.json para facilitar correr la aplicación completa (por ej. un solo comando que inicie backend y frontend en paralelo). Documentar en README u otro doc cómo está dividido el código en módulos y cómo se agrega uno nuevo (guía de contribución para modularidad).

### Dependencias:

Requiere los componentes UI de Fase 1 (para construir las páginas front). Depende también del esquema de base de datos bien definido (posiblemente diseñado en esta misma fase tomando insumos del modelo conceptual definido en documentos). La autenticación probablemente depende de tener usuarios en la base de datos; es decir, hay una ligera dependencia en que el modelado de datos esté listo al empezar a codificar. Fase 2 se apoya en lo logrado en Fase 0 (estructura de proyecto) y sienta las bases para integrarse plenamente en Fase 3.

### Herramientas y librerías recomendadas:

- **Prisma ORM con PostgreSQL:** ya elegido, aquí se aprovecha para generar migraciones y consultas tipadas. Prisma facilita que cualquier cambio en la estructura de datos se refleje en tipos TypeScript compartidos.
- **Passport JWT (NestJS Guards):** Para implementar autenticación en NestJS de forma estandarizada. NestJS ofrece guardias JWT y estrategias de Passport listas para usar, lo que agiliza mucho el módulo Auth. Herramientas: @nestjs/passport, passport-jwt y @nestjs/jwt.
- **Bcrypt** (u otro algoritmo) para hash de contraseñas en AuthService.
- **class-validator y class-transformer** en los DTOs de NestJS: esto permite definir validaciones de datos de entrada de forma declarativa en los DTOs de cada módulo (por ejemplo, requiriendo campos obligatorios, formatos de email, etc.). Se empiezan a usar en esta fase para asegurar la forma correcta de los datos en cada endpoint, aunque el manejo de errores y mensajes se afinará en la fase siguiente.
- **Axios en el frontend:** establecer un cliente HTTP único para consumir la API. Configurarlo con interceptores ahora (por ejemplo, para adjuntar el token JWT a cada petición automáticamente) facilitará la integración en fase 3.
- **React Query (TanStack Query):** incorporar su uso para las pantallas que en el futuro consuman datos del backend. En esta fase, se pueden preparar hooks como `useQuery(['clases'], ...)` que por ahora devuelven datos ficticios o usan `enabled: false` hasta que la integración real esté lista. Así, las páginas ya manejan estados de carga/error de forma consistente.
- **React Hook Form** (opcional): Para formularios de login, registro, pagos, etc., una librería como React Hook Form o Formik puede facilitar gestión de estados de formulario y validación en el frontend. Su introducción en esta fase permite que los formularios de Auth y Pagos sean más robustos, sin duplicar lógica de manejo de inputs en cada componente.

### Criterios de validación y cierre de fase:

- **Modularidad lograda:** El código está organizado en módulos de dominio claramente separados. Por ejemplo, toda la lógica y rutas de autenticación están en auth y no mezcladas con otras. Esto sigue los principios de alta cohesión y bajo acoplamiento: si se necesita tocar algo de pagos, se sabe exactamente qué carpeta revisar, sin dependencias circulares entre módulos.
- **Funcionalidad básica comprobada:** Se puede ejecutar el backend y realizar una serie de operaciones simples exitosamente, aunque no estén al 100% integradas. Ejemplos de validación: Registrar un nuevo usuario vía API devuelve un resultado esperado (e inserta en la base de datos), obtener la lista de clases devuelve una estructura coherente (aunque sean datos de prueba), invocar un endpoint de pagos inicia un flujo (simulado) sin error. Para cada módulo principal, una ruta clave funcionando.
- **Frontend navegable (modo simulado):** Levantando la aplicación Next.js, el desarrollador puede navegar a la página de login, a un dashboard de clases, etc., y la UI se muestra correctamente usando componentes reales. Aunque aún no esté conectada al backend, la aplicación permite una navegación "de punta a punta" con datos simulados. (Por ejemplo, después de "loguearse" se muestra el dashboard de estudiante con una lista estática de clases).
- **Sincronía entre front y back en estructura de datos:** Las interfaces o tipos de datos que representan, por ejemplo, un Usuario o una Clase, están acordes en front y back. Idealmente, ya se comienza a compartir definiciones o a reflejar en TypeScript lo definido en los DTOs del backend. Aún si los datos son mock, un desarrollador podría comparar un objeto JSON de Clase devuelto por el back con lo que el front espera y ver consistencia.
- **Cobertura de pruebas incipiente:** Aunque la mayor parte del testing vendrá después, se comprueba que los módulos nuevos incluyen al menos pruebas unitarias básicas en backend. Todos estos tests (y los de componentes de fase 1) siguen pasando.
- Con esto, la plataforma tiene esqueleto completo: todas las piezas principales están identificadas y creadas, listos para ser conectados entre sí en la siguiente fase. Un checkpoint con commit y quizá una revisión de arquitectura se realiza antes de proceder.

## Fase 3: Integración de API, validaciones y contratos de tipos compartidos

**Objetivo técnico:** Conectar completamente frontend y backend, de modo que los módulos construidos cobren vida con datos reales y reglas de negocio completas. En esta fase se implementan todas las integraciones de API necesarias: el frontend comienza a consumir los endpoints reales del backend para autenticación, datos de clases, pagos, etc. Se refina la lógica de negocio en backend (añadiendo validaciones más estrictas, manejos de error completos) y se asegura que los contratos de datos (DTOs y tipos TypeScript) se mantengan sincronizados entre backend y frontend. En esencia, se pasa del "esqueleto" a un sistema cohesionado donde las piezas encajan perfectamente y hablan el mismo idioma.

### Artefactos esperados:

- **Conexión Front-Back establecida:** El código frontend realiza llamadas HTTP reales al backend para las funcionalidades clave. Artefactos: implementación de llamadas mediante Axios o fetch en los hooks/páginas del front. Ejemplos: la página de login utiliza un servicio `authService.login(credentials)` que hace POST /auth/login al NestJS y guarda el JWT; la página de clases usa `useQuery('clases', ...)` que fetch a /api/clases y muestra datos reales desde la BD.
- **Validaciones robustas de entrada y salida:** En el backend, todos los endpoints ahora usan DTOs con validaciones de class-validator para entradas (lanzando errores 400 claros si algo es inválido). En el frontend, se integran validaciones de formularios para proporcionar feedback inmediato al usuario (por ejemplo, usar Yup/Zod con React Hook Form para validar campos antes de enviar). Artefacto: mensajes de error claros en ambos lados y manejo de esos errores (p.ej., mostrar "email ya registrado" en el UI si la API devuelve un error correspondiente).
- **Contratos de tipos unificados:** Se establece una fuente única de verdad para los tipos de datos compartidos entre front y back. Artefactos posibles:
  - Un paquete o módulo @mateatletas/shared-types dentro del monorepo que exporta interfaces/Tipos TypeScript para las entidades y DTOs (por ejemplo, User, Class, EnrollmentDTO, etc.), de modo que el backend las implementa y el frontend las reutiliza.
  - Alternativamente, generar automáticamente los tipos TS a partir del esquema de la API (usando Swagger/OpenAPI generado por NestJS y una herramienta como openapi-typescript).
  - En cualquier caso, el resultado es que si se añade o cambia un campo en un DTO backend, el front lo reconoce inmediatamente en compilación. Por ejemplo, si backend espera `clase_id: number`, el frontend no podrá compilar si envía un string. Esta sincronización elimina una categoría entera de bugs antes de que ocurran en producción.
- **API completa según requerimientos:** Todos los endpoints necesarios para las funcionalidades definidas están implementados en NestJS y funcionando correctamente. Por ejemplo: registro/login, CRUD de clases (listar clases disponibles, inscribir a estudiante a una clase), operaciones de pagos (crear pago, webhook de confirmación si aplica), asignación de puntos/logros de gamificación, etc. Artefacto: Colección de API (por ej. colección Postman o Swagger UI) que documenta cada endpoint, sus parámetros y respuestas. La API debería reflejar el API v1.0 planeado.
- **Manejo de estados y sincronización:** En frontend, se afinan los stores y estados para reflejar datos reales. Ej.: el Zustand store de autenticación ahora guarda el token real y datos del usuario tras login, y provee métodos para logout (limpiando estado). Otro ejemplo: después de que un tutor inscribe a un estudiante en una clase (acción en frontend que llama al backend), el estado global o cache de React Query se actualiza para reflejar que esa clase tiene un cupo ocupado adicional, etc. Se implementan mecanismos de sincronización de datos (invalidar caches tras mutaciones, etc.) para mantener coherencia entre cliente y servidor.
- **Seguridad end-to-end:** Aplicar medidas de seguridad en serio: protección de rutas en el frontend (redireccionar al login si no autenticado, etc.) y verificación de autorizaciones en backend para cada endpoint sensible (usando los Guards y roles). Artefacto: Por ejemplo, un guard en Nest que verifica roles (ya implementado para docentes, tutores, etc.) y en front un componente `<PrivateRoute>` o uso del middleware/route handling de Next.js para restringir el acceso a ciertas páginas si no hay sesión.
- **Gestión de errores y edge cases:** Completar la lógica de negocio para casos no felices. Ejemplos: no permitir inscripción a clase si el cupo está lleno (debe dar error desde backend y manejarse en front mostrando mensaje apropiado). Procesar webhooks de pago (si se utilizan) para activar membresías. Asegurarse de que las transacciones de base de datos se manejen correctamente en operaciones complejas (quizás usando transactions de Prisma para operaciones multi-tables).
- **Documentación actualizada:** Actualizar o completar la documentación técnica para reflejar los contratos finales de la API. Si se usa Swagger (NestJS puede generar documentación OpenAPI automáticamente), publicar ese JSON o UI como documentación viva de la API. Además, anotar en la documentación decisiones tomadas durante la integración (por ejemplo, "decidimos implementar la validación X en backend en lugar de front por Y motivo", etc.).

### Dependencias:

Esta fase se basa en todo lo anterior: requiere que los módulos existan (Fase 2) y que los componentes UI estén disponibles (Fase 1). También depende de que el modelo de datos sea sólido. Es interdependiente: a medida que se integran front y back, pueden descubrirse necesidades de ajuste en esquemas o endpoints, lo que a su vez requiere coordinar entre ambos lados. Por ello, la comunicación (o en nuestro caso, la sincronización de tipos y buena planificación) es crucial.

### Herramientas y librerías recomendadas:

- **Swagger (NestJS)** para documentación de API: Decorar los controladores y DTOs con anotaciones Swagger de modo que se genere una especificación OpenAPI. Esto sirve para compartir con el equipo y verificar que el contrato es el esperado.
- **OpenAPI Codegen / openapi-typescript:** En caso de optar por generación de tipos automática para frontend, usar estas herramientas en la pipeline para regenerar tipos cuando cambie la API. Alternativamente, explorar tRPC si se quisiera un enfoque de contratos de tipos compartidos de forma automática (RPC fuertemente tipado), aunque incorporar tRPC a un Nest + Next tradicional no es común, podría evaluarse.
- **class-validator** (ya mencionada) y Joi (opcional) para validación adicional: NestJS ya usa class-validator para la capa de transporte, pero también podríamos usar Joi u otra librería al nivel de lógica de negocio si se requieren validaciones más complejas en servicio.
- **Sentry** u otra herramienta de monitoreo (opcional esta fase, quizá próxima): Si es posible, integrar ahora monitoreo de errores en frontend y backend para empezar a registrar fallos reales durante las pruebas integrales. No afecta la funcionalidad, pero es buena práctica de calidad.
- **NestJS e2e testing module:** NestJS permite montar la aplicación en modo de prueba. Se puede usar SuperTest junto con Jest para escribir pruebas de integración que llamen a varios endpoints reales verificando su interacción. Esto se puede iniciar en esta fase (por ejemplo, pruebas que simulan un flujo entero: registrar usuario, hacer login, llamar a obtener perfil con el token). Esto complementa la verificación manual y será formalizado en Fase 4.

### Criterios de validación y cierre de fase:

- **Flujos funcionales end-to-end comprobados:** Al término de la fase, un usuario de prueba debería poder atravesar los escenarios principales en un entorno de staging local: Registrarse, loguearse, navegar su dashboard, inscribirse a una clase, realizar un pago (aunque sea simulado), y obtener puntos o logros. Todo esto usando la UI real conectada al backend real. Cada acción del usuario en pantalla produce los efectos esperados en la base de datos y en la propia interfaz (ej. tras inscribir a clase, el botón "Inscribirme" cambia a "Inscripto" y la base de datos refleja la nueva inscripción).
- **Consistencia de datos garantizada:** Gracias al contrato de tipos compartido, cualquier discrepancia entre front y back se habría detectado durante el desarrollo. La compilación de TypeScript en ambos lados es exitosa y las integraciones no muestran errores de tipo. Si hubo que ajustar campos o nombres, ambos lados se actualizaron al unísono. Esta coherencia es un indicador clave de éxito en la fase.
- **Validación de seguridad y reglas de negocio:** Se prueba que las restricciones funcionan: por ejemplo, un tutor no puede acceder a endpoints reservados a docentes (devuelve 403 Forbidden apropiadamente), no se puede inscribir dos veces al mismo estudiante en la misma clase (la API devuelve error y el front maneja esa situación), etc. Estas pruebas pueden hacerse manualmente o con scripts, pero deben pasar antes de cerrar la fase.
- **Cobertura de pruebas de integración satisfactoria:** Idealmente, existe un conjunto de pruebas automatizadas que verifican los principales contratos. Por ejemplo, una prueba que haga un POST /auth/login con credenciales válidas y compruebe que devuelve 200 y un token, otra que haga GET /api/clases y espere cierto esquema de datos, etc. Estas pruebas de integración demuestran objetivamente que front y back están alineados.
- **Documentación de API y guía de uso actualizada:** Los desarrolladores (o agentes de IA) que tomen el proyecto en este punto deberían contar con un documento de referencia (Swagger UI, Markdown o similar) que liste todos los endpoints, sus parámetros, y estructuras de respuesta. Además, la documentación interna (README, Notion, etc.) debe reflejar cualquier cambio de decisión técnica surgido en la integración, evitando información obsoleta.
- Con todo lo anterior, el MVP de la plataforma está funcional a nivel técnico. Esta fase concluye al lograr un sistema cohesionado y listo para ser rigurosamente testeado y refinado.

## Fase 4: Testing unitario, integración y E2E

**Objetivo técnico:** Garantizar la calidad del sistema mediante la implementación de una estrategia de testing integral (unitario, integración y end-to-end). Aunque se han ido escribiendo pruebas en fases anteriores, en esta etapa se completa la pirámide de pruebas, cubriendo todas las capas de la aplicación. Se busca detectar y corregir cualquier bug o inconsistencia antes de lanzar el producto, asegurando que tanto el frontend como el backend, y su interacción, funcionen según lo previsto bajo múltiples escenarios.

### Artefactos esperados:

- **Pruebas unitarias exhaustivas (backend):** Ampliación de la batería de tests unitarios para cada servicio y componente aislado. Artefacto: archivos .spec.ts en Nest que cubren todos los métodos importantes de los servicios (por ejemplo, pruebas de que InscripcionesService.crearInscripcion() maneja correctamente casos de éxito y error). Estas pruebas utilizan mocks para aislar dependencias (mock de Prisma, etc.). El objetivo es que la lógica interna de cada módulo quede validada en todos los casos de borde posibles.
- **Pruebas unitarias/funcionales (frontend):** Tests con Vitest/Jest y React Testing Library que comprueban la funcionalidad de componentes complejos y hooks. Ejemplos: probar que el formulario de login muestra mensajes de error locales al ingresar datos inválidos, o que el hook `useEnrollClass` llama al endpoint correcto y actualiza estado global apropiadamente. Pueden incluir pruebas con DOM simulado para eventos de usuario en componentes.
- **Pruebas de integración (backend):** Utilizando la aplicación NestJS levantada en modo de prueba y una base de datos de test separada (Prisma facilita cambiar de DB con variable de entorno), escribir tests que abarcan de controlador a base de datos. Artefacto: por ejemplo, un test para POST /api/inscripciones que: prepara datos en una BD de prueba, llama al endpoint real usando Supertest, y verifica que la respuesta HTTP es correcta y que la base de datos efectivamente registró la inscripción. Estos tests validan la integración interna del backend (sus distintos módulos y la BD).
- **Pruebas end-to-end (E2E) del sistema completo:** Scripts de prueba automatizados que simulan acciones de un usuario final en la aplicación desplegada o en un entorno de staging. Artefacto: casos de prueba con Playwright o Cypress que abren un navegador, navegan la aplicación Next.js como lo haría un usuario y verifican que todo funciona. Ejemplo: un script que abre la página de login, inicia sesión con credenciales de prueba, luego navega al listado de clases, reserva una clase, va a la sección de logros, etc., verificando en cada paso que aparece la UI esperada y, de ser necesario, corroborando en la base de datos que los cambios tuvieron lugar. Estos tests E2E actúan como la última capa de confianza, probando el sistema como un todo.
- **Informe de cobertura y calidad:** Generación de reporte de cobertura de código (utilizando Istanbul/nyc integrado con Jest/Vitest). Se espera tener un porcentaje alto de cobertura en unidades críticas (idealmente > 80% en backend core y lógica de frontend). Más que el número, interesa que no queden rutas críticas sin probar. Artefacto: reporte de cobertura (HTML, lcov) revisado por el equipo.
- **Integración continua de pruebas:** Configuración final de la canalización CI para que ejecute toda la suite de tests automáticamente en cada push o PR. Esto incluye paralelizar si es posible (por ejemplo, correr unit tests y e2e en paralelo en distintos jobs). Artefacto: archivos de CI (YAML de GitHub Actions u otro) actualizados para correr `npm test` (y quizás `npm run e2e` por separado) y almacenar resultados/artefactos (logs, screenshots de fallos de Playwright, etc.).
- **Refinamiento basado en pruebas:** Durante esta fase seguramente se refactoriza o corrige código para resolver bugs descubiertos. Cada bug corregido idealmente añade un caso de prueba que impida su reaparición. Un artefacto importante aquí es el registro de bugs y su resolución: documentar brevemente los problemas encontrados y cómo se solucionaron, ya sea en comentarios de commits, en un CHANGELOG o en tickets.

### Dependencias:

Todo el sistema debe estar integrado (Fase 3 completa) para poder probar end-to-end. También depende de tener datos de prueba realistas: será útil cargar fixtures o datos semilla en la base de datos de test (por ejemplo, usuarios de prueba, clases de ejemplo) para poder ejecutar pruebas. Esta fase idealmente se ejecuta en paralelo al final de Fase 3 (mientras se integran cosas, se van creando pruebas), pero formalmente depende de la funcionalidad terminada para probarla completamente.

### Herramientas y librerías recomendadas:

- **Jest** (viene por defecto con Nest) para tests unitarios e integración en backend. Su entorno ya está configurado para TypeScript. Utilizar utilidades de Nest como TestingModule para arrancar módulos en pruebas de integración.
- **Vitest** para tests del frontend, ya que es más rápido en recarga que Jest y se integra bien con Vite/Next (si Next.js está usando Webpack, también se puede usar Jest pero Vitest es una opción moderna). Incluir React Testing Library para simular interacciones de usuario en componentes.
- **Supertest** para hacer peticiones HTTP simuladas a la API Nest (en tests de integración y algunos E2E simples).
- **Playwright o Cypress** para pruebas E2E del frontend+backend. Playwright tiende a ser rápido y permite pruebas multi-page y funcionalidades avanzadas; Cypress es también popular y con buena DX. Cualquiera sirve; lo importante es automatizar escenarios completos.
- **msw (Mock Service Worker)** (opcional en tests front): Para tests unitarios de componentes que hacen fetch, se puede usar msw para simular las respuestas del backend sin realmente levantarlo. Esto agiliza los tests de front sin perder realismo en las llamadas.
- **Testing Pyramid** concepto guía: priorizar muchos tests unitarios (rápidos), algunos de integración, y menos E2E (más lentos), pero cubriendo al menos un flujo por funcionalidad clave. Esto garantiza feedback rápido de fallos y cobertura amplia con eficiencia.

### Criterios de validación y cierre de fase:

- **Suite de tests pasando al 100%:** No debe haber fallos en ninguna prueba al final de esta fase. Un build de CI debe mostrar verde en todos los jobs de testing.
- **Cobertura de código adecuada:** Se alcanza o supera el porcentaje objetivo de cobertura. Más importante, se verifica manualmente que las partes críticas (autenticación, pagos, etc.) están cubiertas por casos de prueba. Si algo no puede ser probado automáticamente (ej. la integración con MercadoPago real), se documenta cómo se testea manualmente.
- **Resiliencia demostrada:** Las pruebas E2E ejecutadas en repetidas ocasiones pasan consistentemente, demostrando que el sistema maneja correctamente los estados. Por ejemplo, una prueba que corre 5 veces crear y cancelar pagos no deja la base de datos en estado inconsistente ni produce errores intermitentes. Esto infunde confianza de estabilidad.
- **Corrección verificada de bugs:** Cualquier bug identificado durante la fase tiene una prueba asociada que confirma su arreglo. La aplicación cumple con los requisitos funcionales establecidos, tal como validado por los tests que esencialmente codifican esos requisitos.
- **Go/No-Go listo:** Con todos los tests en verde y documentación de pruebas lista, se puede decidir avanzar a optimización y despliegue. Esta fase cierra formalmente cuando el equipo está satisfecho de que la calidad es lo suficientemente alta para presentar el producto, al menos internamente. Un informe de prueba final o una reunión de repaso de calidad puede marcar la aceptación de la fase.

## Fase 5: Refactor, documentación viva y optimización

**Objetivo técnico:** Realizar una pasada final de refactorización y mejoras de calidad, junto con la consolidación de la documentación viva del proyecto y optimizaciones de rendimiento u otras antes de lanzar. Aquí se abordan cualquier deuda técnica menor pendiente, se mejora la legibilidad y mantenibilidad del código, y se asegura que toda la documentación refleja fielmente el estado actual del sistema. También se optimiza la aplicación para producción (performance, seguridad y despliegue).

### Artefactos esperados:

- **Refactor de código crítico:** Limpieza de secciones de código que se identificaron como subóptimas. Artefacto: commits específicos de refactor (sin cambiar funcionalidad) que mejoran aspectos como duplicación de código, nombres de variables más claros, separación de responsabilidades, etc. Por ejemplo, si en fase 3 se escribieron validaciones similares en múltiples lugares, ahora centralizarlas en un helper único; o si un componente frontend creció demasiado, separarlo en subcomponentes.
- **Organización impecable del repositorio:** Verificar y ajustar la estructura de carpetas si es necesario para que siga siendo lógica. A estas alturas, la estructura modular debe permanecer clara. Por ejemplo, puede crearse una carpeta `libs/` compartida si surgieron más utilidades comunes. Todos los módulos y capas siguen el patrón consistente definido (si algún módulo difiere sin razón, homogenizarlo).
- **Mejoras de rendimiento:** Optimizar consultas y carga donde se pueda. Artefacto: por ejemplo, añadir índices a tablas SQL identificadas como lentas (basado en pruebas de carga ligeras o análisis), ajustar configuraciones de Prisma (pool de conexiones adecuado), implementar lazy loading en frontend para módulos pesados o dividir el bundle de Next.js para que la carga inicial sea más rápida. Correr una pasada de Lighthouse en la aplicación web y optimizar puntajes de performance y accesibilidad si es pertinente.
- **Preparación para producción:** Configurar correctamente la aplicación para entornos reales. Artefactos: archivos de configuración de build/deploy (Dockerfile si se usará contenedores, adaptaciones en código para variables de entorno de producción, etc.). También setear medidas de seguridad: HTTPS, variables seguras, políticas de CORS adecuadas, rate limiting en API (Nest rate-limiter guard si necesario), etc.
- **Documentación "viva" completa:** Actualización final de todos los documentos para que estén en sincronía con la versión actual del sistema. Esto incluye:
  - **Documentación de arquitectura:** un documento (o wiki) que recoja las decisiones técnicas tomadas y por qué. Idealmente usando un formato de ADR (Architectural Decision Records) para listar decisiones clave (e.g., "Decidimos monorepo Nx por motivo X", "Se eligió Tailwind por Y", "Se estructura módulos de dominio según Clean Architecture, etc.").
  - **Mapeo de features a commits/tests:** Un registro donde por cada funcionalidad importante se referencia el commit donde se implementó y las pruebas asociadas que la cubren. Esto podría lograrse mediante mensajes de commit claros (ej. incluyendo ID de historia de usuario) o manteniendo una sección en la documentación que diga "Feature X (commit hash) – ver pruebas en archivo ...spec.ts". El objetivo es trazabilidad: poder rastrear la evolución de cada requerimiento en el código.
  - **Manual de despliegue y operaciones:** Incluir pasos para desplegar la aplicación (por ejemplo, cómo ejecutar migraciones de Prisma en producción, cómo configurar variables de entorno en el servidor, etc.), así como procedimientos de rollback.
  - **Docs para nuevos desarrolladores:** Un Developer Guide que sirva a futuros colaboradores o agentes de IA para entender rápidamente la arquitectura y poner en marcha el proyecto localmente. Mucho de esto ya se tiene de fases previas, pero ahora se consolida y verifica que esté actualizado.
- **Sincronización de contratos garantizada en adelante:** Implementar mecanismos para mantener la sincronía de contratos de tipos de forma automática si es posible. Artefacto: por ejemplo, un script en CI que falle si los DTOs de backend han cambiado sin actualizar los tipos compartidos en frontend. O al menos, documentar el proceso para que cada cambio en API conlleve actualizar la librería de tipos compartidos. La documentación debe resaltar este proceso para no romper la coherencia lograda.
- **Optimización continua asistida por IA:** Dado que el desarrollo es asistido por IA, establecer pautas para que los agentes de IA sigan mejorando el código sin introducir regresiones. Artefacto: quizás reglas adicionales para herramientas de static analysis o pruebas de calidad (como SonarQube reportes, etc.), de modo que cualquier sugerencia de refactor de una IA pase ciertos checks antes de aplicarse. (Este punto es opcional, orientado a cómo seguir trabajando con IA de forma segura.)

### Dependencias:

Es la etapa final y depende de todo lo anterior completado. No se inicia hasta que los tests de fase 4 estén mayormente en verde y el producto funcional esté feature-complete. Se alimenta también de cualquier feedback de rendimiento o revisión de código externa.

### Herramientas y librerías recomendadas:

- **Linting y formato estricto:** Re-ejecutar linters y posiblemente usar herramientas como TSLint/ESLint rulesets más estrictos o Prettier para uniformidad máxima.
- **SonarQube/SonarCloud** (opcional): para una pasada de análisis estático de calidad y seguridad del código, detectando posibles code smells, duplicaciones, puntos de mejora.
- **Profiler de DB:** utilizar EXPLAIN en consultas SQL complejas via Prisma or logs de Prisma para identificar optimizaciones (añadir índices, etc.).
- **Bundle Analyzer:** para Next.js, usar `next build --analyze` para inspeccionar tamaño de bundles y realizar code splitting o eliminar dependencias no usadas.
- **Postman/Newman** o integration tests para hacer smoke tests pre-deployment: básicamente volver a correr pruebas de integración quizá contra un entorno staging preparado con versión de producción.
- **Docker/Kubernetes** (si aplica): containerizar la app para desplegarla consistentemente. Esta herramienta depende del stack ops, pero es bueno incluir configuración Docker en el repo.
- **Continúa integración y despliegue (CI/CD):** Ampliar el pipeline de CI para CD (Continuous Deployment), por ejemplo desplegando en Vercel el front y en un servicio cloud el backend, o construyendo imágenes Docker y subiendo a algún registry. Esta configuración se documenta para que el sistema de despliegue quede reproducible.

### Criterios de validación y cierre de fase:

- **Código limpio y mantenible:** Revisiones finales de código confirman que no hay "malos olores" obvios. Cualquier desarrollador/IA leyendo el código debería entender la estructura fácilmente gracias a la consistencia. Tipo de verificación: Code review interna o incluso ejecutar una herramienta de análisis y ver que el puntaje de mantenibilidad es bueno.
- **Documentación sincronizada con el producto:** Al leer la documentación técnica, no hay contradicciones con respecto al comportamiento real del sistema. Cada decisión importante que uno vea en el código aparece explicada en algún documento. Los contratos de API y tipos en la doc coinciden con los del código (gracias al uso de DTOs como documentación viva). También, se puede mapear cualquier feature o cambio a su correspondiente registro (commit o nota) de forma sencilla, mostrando trazabilidad completa.
- **Rendimiento aceptable:** Se han realizado pruebas de carga básicas o medido rendimiento del frontend. Por ejemplo, comprobar que una página con 100 clases carga en pocos segundos, o que el servidor puede manejar, digamos, 50 peticiones concurrentes sin degradación notable. No se busca una optimización prematura extrema, pero sí que la app cumpla con requisitos no funcionales mínimos (tiempos de respuesta, etc.). Si se halló algún cuello de botella en pruebas, fue mitigado.
- **Preparación para escalabilidad:** La arquitectura modular y las prácticas implementadas aseguran que añadir un nuevo módulo o funcionalidad no rompa las existentes. Un criterio aquí podría ser hipotético: "¿qué tan fácil es ahora incorporar un nuevo módulo X?" Si la respuesta es "seguimos los patrones ya establecidos, con confianza en tests y tipos compartidos", entonces la fase de refactor logró solidificar la arquitectura escalable.
- **Checklist de lanzamiento completa:** Antes de dar por concluido, verificar que todos los checklists de calidad se cumplieron: todos los tests OK, docs ok, entorno de producción configurado, no hay issues de seguridad pendientes, etc. Con eso, se puede declarar que la versión 1.0 está lista.

## Estrategia de Testing Continuo 📊

Una piedra angular del desarrollo progresivo de Mateatletas es la integración continua de pruebas en cada fase del ciclo de vida, sin relegarlas al final. Esto garantiza calidad desde el inicio y evita desviaciones. La estrategia sigue el modelo clásico de la Pirámide de Pruebas, adaptado a nuestras fases:

- **Fase 0-1 (Setup y UI):** Se configuran frameworks de testing (Jest/Vitest) en el monorepo desde el principio. En la fase 1 ya se escriben pruebas unitarias de componentes UI (por ejemplo, que un botón renderiza con el texto correcto o que un componente Modal abre y cierra cambiando el estado). Estas pruebas iniciales aseguran que la base de la UI es sólida y previenen regresiones en componentes reutilizables. Se mantienen ligeras para no obstaculizar la creatividad: por ejemplo, snapshots o tests de render simple, ejecutados en segundos cada vez que un componente cambia.

- **Fase 2 (Módulos funcionales):** A medida que se construyen servicios backend y lógica de frontend (ej. hooks), se implementan tests unitarios de lógica. En el backend, por cada método crítico de los servicios se crea un test correspondiente usando mocks de dependencias. En el frontend, si se crea, digamos, un hook `useCalculatePoints`, se le escriben tests con distintos escenarios. El enfoque aquí es desarrollo dirigido por pruebas en lo posible para lógica compleja: por ejemplo, escribir casos de prueba para la asignación de puntos de gamificación antes de codificarla, asegurando comprender la especificación. Estas pruebas unitarias corren rápido y dan confianza en cada pieza aislada.

- **Fase 3 (Integración):** Al conectar frontend y backend, se incorporan pruebas de integración. En backend, tests que cubren desde el controlador hasta la base de datos como un todo (arrancando un módulo Nest completo con base de datos de prueba). En frontend, se pueden escribir tests de integración usando un servidor de pruebas del backend (o simulando con msw) para verificar que un flujo de datos funciona: por ejemplo, montar un componente de lista de clases que en su useEffect hace fetch real a /api/clases (apuntando a una instancia de la API de prueba) y comprobar que tras resolver la promesa los datos aparecen en pantalla. Además, se puede empezar con tests contractuales: por ejemplo, verificar que la respuesta de cierto endpoint contiene campos que el frontend espera (esto puede hacerse con un schema JSON en tests backend o simplemente mediante los types compartidos). La idea es detectar cualquier desalineación de contrato inmediatamente.

- **Fase 4 (Testing intensivo):** Se consolida todo en una suite completa. Las pruebas E2E se ponen en marcha para probar como un usuario real. Estas pruebas end-to-end no es necesario correrlas a cada cambio menor (porque son más lentas), pero sí en cada push importante o al menos diariamente en CI, para asegurarnos de que el sistema completo sigue coherente. Mientras tanto, los tests unitarios e integración se ejecutan con cada cambio (incluso en modo watch durante el desarrollo local, para feedback inmediato). La automatización está configurada para que al hacer commit o abrir un PR, se ejecuten linters y tests automáticamente, evitando introducir errores en el repositorio principal. Esto no interfiere con el ritmo creativo porque los desarrolladores/IA pueden ejecutar tests localmente cuando lo deseen, y la CI los corre en segundo plano; además, al haber escrito pruebas desde fases tempranas, ya existen casos que cubren la mayoría de funcionalidades, evitando "pánico" de último momento.

- **Fase 5 (Refactor):** Se siguen corriendo toda la batería de pruebas con cada refactor para asegurarse de no romper nada. Además, se puede añadir tests de rendimiento (no funcionales) si se desea, por ejemplo usando scripts de carga para ver cómo responde la API bajo stress. Cualquier hallazgo puede traducirse en un test o monitor (por ejemplo, si descubrimos un bug al crear 100 usuarios concurrentes, añadir un test de esa condición). La suite de pruebas se convierte en parte de la documentación viva del sistema: especifica de forma ejecutable cómo se espera que funcione cada pieza.

### Herramientas de testing en el entorno:

Como se mencionó, utilizamos Vitest/Jest para unidades, Jest + Supertest para integración API, y Playwright/Cypress para E2E. En particular, Jest ha sido preferido en backend por su integración out-of-the-box con NestJS, mientras que en frontend se puede usar Vitest por velocidad. Testing Library aporta buenas prácticas de pruebas en React (enfatizando la experiencia del usuario al buscar elementos por texto/rol en lugar de detalles de implementación). Playwright ofrece un runner propio que puede integrarse en la CI para lanzar un navegador headless y simular clics y navegación de forma robusta.

### Automatización sin frenar la creatividad:

Es crucial que la automatización trabaje en segundo plano. Para ello:

- Se configura posiblemente Husky para que antes de hacer push, ejecute los tests unitarios rápidamente. Si tardan mucho, al menos ejecutar linters y un type-check completo (que ya valida mucho). Los tests completos pueden delegarse a la CI tras el push, manteniendo al desarrollador libre para seguir codeando.
- La CI está diseñada para proveer feedback rápido: por ejemplo, paraleliza la ejecución de tests de backend y frontend. Un fallo en tests genera reportes claros (con logs, screenshots si E2E falla, etc.) que facilitan a un agente de IA identificar y corregir el problema.
- No se exige 100% coverage a cada commit intermedio (eso puede interrumpir creatividad); en vez de eso, se aplica un criterio incremental: cada fase tiene requerimientos de testing acordados. Por ejemplo, al terminar Fase 2, se espera cierta cobertura en nuevos módulos. Así, los desarrolladores/IA pueden enfocarse en la lógica primero y luego en los tests, sin posponerlos indefinidamente. Es un balance guiado por la pirámide: primero asegurar núcleo con unit tests, luego expandir.

### Validación de coherencia entre backend, frontend y datos:

La estrategia de pruebas está diseñada para verificar constantemente la alineación entre las distintas capas:

- El uso de TypeScript compartido ya garantiza en tiempo de compilación que muchos desacoples no ocurran (un error de tipo es atrapado antes de ejecutar). Esto es un nivel de verificación continuo mientras se desarrolla.
- Las pruebas de integración y E2E actúan como verificación dinámica: si por ejemplo el frontend espera un campo `precio_base` en la respuesta de productos pero el backend lo llama `base_price`, un test de integración/E2E que ejecute ese flujo detectará el fallo (o incluso un simple type-check si se comparte la definición). Aseguramos que todas las definiciones de DTOs (Nest) e interfaces (Next) concuerdan ejecutando tests que serializan/deserializan datos reales.
- También podemos implementar contract testing estilo consumer-driven: crear, por ejemplo, en el frontend un mock de la API que siga la especificación esperada y validar contra el real. Pero en nuestro contexto, compartir tipos y hacer integración directa en monorepo ya cubre esto de forma más sencilla.
- Finalmente, los tests E2E validan la coherencia completa: desde la entrada de datos por parte del usuario en la interfaz, hasta cómo viaja a la API y se guarda en la base de datos, retornando a la interfaz. Un error de incoherencia (como un campo faltante en la UI o un cálculo distinto en front vs back) se manifiestará en estos tests de punta a punta. Como ejemplo, en el backend definimos que al inscribir a un estudiante se debe incrementar el contador de cupos ocupados de la clase; un test E2E puede comprobar que tras la inscripción, la interfaz del tutor muestra el cupo actualizado, confirmando que tanto el backend hizo su trabajo en la BD como que el frontend interpretó y reflejó correctamente ese cambio.

En resumen, el testing continuo significa que cada fase incluye su propio objetivo de pruebas y la calidad se construye incrementalmente. Esto no solo asegura un producto final robusto, sino que permite que múltiples agentes (humanos o IA) colaboren en paralelo con confianza, ya que los tests actúan como guardianes inmediatos de integridad ante cualquier integración de código.

## Sistema de Reutilización Progresiva ♻

Para mantener la coherencia y velocidad en un proyecto modular extenso, adoptamos un sistema de reutilización progresiva de componentes y lógica, que se va cimentando desde las primeras fases:

- **Componentes UI y hooks primero:** Como se describió en Fase 1, se construyen todos los componentes atómicos de interfaz al inicio, junto con hooks utilitarios, antes de abordar funcionalidades completas. Esto significa que cuando en fases 2 y 3 se desarrollan las páginas y flujos, los desarrolladores (o agentes IA) no necesitan crear botones o modales desde cero ni resolver problemas de estilo repetidamente; simplemente reutilizan las piezas ya probadas. Este enfoque de Diseño Atómico permite pensar en construir con "lego blocks" predefinidos, logrando velocidad y consistencia visual. Por ejemplo, el mismo componente `<Button>` estándar se usa en todo el sistema para acciones, garantizando comportamiento uniforme (estilos, estados, accesibilidad). Si más adelante se decide cambiar un detalle de estilo, se hace en un solo lugar (el componente) y se refleja en toda la aplicación. Lo mismo ocurre con hooks como `useAuth` – centraliza la lógica de autenticación (login, logout, obtener usuario actual) para que cualquier vista que necesite saber el estado de auth use ese hook en lugar de duplicar lógica. Este hook único puede ser mejorado con el tiempo (ej. agregando manejo de token refresh) y todas las partes de la app se benefician inmediatamente.

- **Funciones y servicios reutilizables estructurados:** A nivel backend, NestJS por naturaleza fomenta crear servicios que encapsulan la lógica de negocio de cada módulo. Esos servicios pueden a su vez ser utilizados por otros módulos si es necesario mediante inyección de dependencias, evitando duplicación. Por ejemplo, un `UsuariosService` con método `findUserByEmail` puede ser usado tanto por Auth (para login) como por el módulo de Usuarios, en lugar de escribir consultas dos veces. En frontend, se organiza código común en helpers o utils y en stores globales cuando tiene sentido. Por ejemplo, si varias páginas necesitan formatear fechas de la misma manera, se crea una utilidad `formatDate()` en un helper común en lugar de formatear en cada componente de forma diferente. Si tanto front como back necesitan la misma lógica (imaginemos la regla de cálculo de nivel de gamificación), se podría colocar en un módulo compartido (p. ej., una función `calcularNivel(puntos)` en `shared/utils.ts`) que el backend y el frontend importan, de modo que ambos lados usan exactamente la misma fórmula. La presencia de un monorepo facilita enormemente este tipo de código compartido, eliminando barreras para la reutilización.

- **Evitar duplicación de lógica mediante contratos y stores centralizados:** Muchas veces la duplicación ocurre entre frontend y backend (ej.: validar formularios en front y luego validar nuevamente en back). Para minimizar esto, definimos claramente responsabilidades: las reglas críticas de negocio se implementan en el backend (fuente de verdad), pero gracias al contrato de tipos y DTOs compartidos, podemos derivar algunas reglas al front sin duplicar completamente. Por ejemplo, un DTO de registro de usuario puede tener la regla "el password requiere 8 caracteres"; podemos reutilizar esa regla en el front simplemente teniendo una copia sincronizada de esa definición (o un esquema de validación compartido). Otro ejemplo: la lógica de autorización (¿puede este usuario acceder a X?) vive en backend, pero el frontend, conociendo el rol del usuario, puede evitar mostrar opciones no permitidas – no es duplicar la regla, sino una optimización de UX; aun así, el guard definitivo es backend. En cuanto a estado compartido, se unifica: en lugar de mantener, digamos, el estado de "usuario logueado" separado en diversas partes, se centraliza en un store (Zustand global, context API). Todas las componentes consumen de ahí, evitando estados desincronizados. Si se requiere que varias vistas muestren la misma información (p. ej., el puntaje actual del estudiante), se expone vía ese store global o mediante React Query cache, en vez de cada componente haciendo su propia petición separada.

- **Construcción incremental de una librería compartida:** A medida que el proyecto crece, identificamos utilidades que pueden moverse a un espacio común. En el monorepo, esto puede significar crear un paquete interno como `libs/commons` o `libs/utils` donde colocar código que aplica a varios módulos. Por ejemplo, tras implementar pagos, quizás descubrimos que la integración con la API de MercadoPago tiene funciones que podrían ser útiles en otros contextos; esas funciones se aíslan en `libs/payments` para su reutilización. Cada fase ofrece la oportunidad de refactorizar en este sentido: antes de duplicar, abstraer. En fase 5 se termina de consolidar esto, pero la mentalidad está desde fase 2: no escribir la misma lógica dos veces. Siempre que surja la tentación de copiar/pegar código, se evalúa moverlo a una función común.

- **Consistencia en la implementación:** La reutilización progresiva también implica que todos los desarrolladores/agentes sigan patrones consistentes para que el código sea coherente. Esto es facilitado por una documentación de patrones (p. ej., "Así se crea un nuevo módulo", "Así se hace un fetch de datos en React Query", etc.). Un beneficio de la modularidad estricta es que cada módulo sirve de ejemplo para el siguiente. Por ejemplo, si ya hicimos AuthModule y luego alguien trabaja en ClasesModule, puede mirar el primero y replicar la estructura. Igual con componentes: una vez definido un estilo de componente (prop types, estructura de carpetas, testing), todos los nuevos componentes siguen ese molde. Esto significa que con el tiempo el proyecto crece, no en complejidad accidental, sino de forma orgánica y controlada. Las mismas convenciones se aplican, lo que reduce bugs y facilita que se puedan intercambiar piezas sin romper el sistema.

En resumen, la filosofía es **"Construir una vez, usar en todas partes"**. Primero construir bien las piezas pequeñas (UI, utils, servicios) y luego ensamblarlas para funcionalidades más grandes, en lugar de programar cada pantalla o flujo como algo único. Esta reutilización progresiva no solo ahorra tiempo, sino que garantiza que la experiencia de usuario y la lógica de negocio sean uniformes en toda la plataforma. Cuando diferentes agentes de IA trabajen en paralelo, esta base compartida reducirá conflictos: todos estarán usando las mismas funciones utilitarias y componentes, así sus contribuciones serán compatibles entre sí por diseño.

## Principios de Documentación Viva 📚

Una arquitectura impecable no solo se ve en el código, sino también en su documentación. Por ello, Mateatletas adopta principios de **documentación viva**, es decir, documentos que evolucionan junto con el sistema y sirven como fuente confiable de verdad en cada etapa. Estos son los pilares de nuestra estrategia de documentación:

- **Registro continuo de decisiones técnicas:** Desde el inicio (fase 0) hasta el final, se mantiene un registro de las decisiones clave. Cada vez que se toma una decisión de arquitectura, stack o incluso una simplificación de implementación, se anota en un archivo de decisiones (siguiendo el formato ADR, por ejemplo) o en la wiki del proyecto. El propósito es que cualquiera (humano o IA) que se una al proyecto más adelante pueda entender por qué el sistema es como es. Ejemplos: decisión de usar NestJS sobre Express, justificación de TypeScript por seguridad y auto-documentación, elección de Prisma vs. otras ORMs, o por qué se implementó cierta lógica en backend y no en front. Estas entradas incluyen fecha y contexto, creando una narrativa de la evolución técnica. La documentación viva aquí significa que incluso si una decisión cambia, se actualiza o se agrega una nueva entrada que refleje ese cambio (manteniendo histórico). No hay documentos muertos: si en fase 2 se dijo "vamos a usar X", pero en fase 4 se cambió a Y, la documentación debe reflejarlo claramente.

- **Mapeo de feature → commit → test:** Este principio busca trazabilidad total. Cada nueva funcionalidad o historia de usuario implementada debe poder rastrearse en el control de versiones y en la suite de pruebas. En la práctica, esto se puede implementar de varias formas complementarias:
  - Los mensajes de commit deben ser descriptivos e idealmente referenciar el ID de la funcionalidad o ticket. Por ejemplo: `feat(clases): permitir cancelar clase (resolves #123)`. De este modo, en el historial git se ve claramente qué commits introducen qué features.
  - Al mismo tiempo, esos commits suelen incluir los tests que cubren la feature. Siguiendo buenas prácticas, en el mismo commit de la feature nueva se agregan o modifican pruebas que la verifican. Así, uno puede buscar en el repo y ver "ah, este test corresponde a la funcionalidad X introducida en tal commit".
  - En la documentación (p.ej., en la descripción de la funcionalidad en el README o wiki), se puede incluso listar: "Funcionalidad X fue añadida en la versión 1.2 (commit hash corto), ver pruebas en archivo clases.e2e-spec.ts caso 'debería cancelar una clase'.". Esto ayuda a que, si alguien está leyendo la documentación de negocio, pueda saltar al código o test relevante directamente.
  - Durante code reviews, se revisa que por cada cambio de lógica importante haya pruebas asociadas y documentación actualizada. Esa es la "definición de done" de cada tarea.

  El resultado es que para cualquier comportamiento del sistema podemos encontrar qué código lo implementa y cómo se verifica. Esto es invaluable cuando múltiples agentes desarrollan partes distintas: si algo falla, el traceo de commit->feature->test acelera identificar quién/qué lo introdujo.

- **Contratos sincronizados entre backend y frontend:** Ya se ha hecho hincapié en compartir DTOs y tipos; esto en sí mismo es documentación viva. Los DTOs en NestJS actúan como documentación ejecutable de la API, definiendo qué espera y produce cada endpoint. Aprovechamos eso generando documentación API (Swagger) directamente del código, evitando discrepancias. En el frontend, las interfaces TypeScript que espejan esos DTOs sirven como documentación para los desarrolladores de frontend sobre qué datos pueden usar. Para mantener este contrato sincronizado:
  - Se establece un flujo de trabajo donde cualquier cambio en un DTO del backend obliga a considerar su efecto en el front. Esto se puede garantizar mediante revisiones de código conjuntas (un PR que cambia un DTO debe pasar por un dev backend y uno frontend, por ejemplo) o mediante herramientas de consistencia (tests o generación de tipos).
  - Posiblemente se integra en CI una verificación de esquema: por ejemplo, usando la salida OpenAPI del backend y comparándola con un esquema esperado por el front (esto es más complejo, pero opcional).
  - Además, la documentación (en un archivo MD o en Swagger UI) de cada endpoint incluye ejemplos de request/response actualizados automáticamente o manualmente cada vez que algo cambia. Esto actúa como contrato legible.

  El principio general es que la única fuente de verdad del contrato es el código mismo, y la documentación derivada siempre proviene de él. No se mantienen documentos de API escritos a mano separados del código, porque tienden a quedar obsoletos; en lugar de eso, se genera del código o se comenta en el código con claridad.

- **Auto-documentación con TypeScript y buenas prácticas:** Se fomenta escribir código auto-explicativo, lo cual es otra forma de documentación viva. TypeScript, por ejemplo, hace que el código sea más auto-documentado al explicitar formas de datos y contratos. Adicionalmente:
  - Se usan JSDoc/TSDoc en funciones y clases públicas para describir su propósito, de forma que un desarrollador obtenga esa info al hover en el editor. Estas anotaciones se mantienen al día cada vez que la funcionalidad cambia.
  - Se podrían generar páginas de documentación técnica a partir de estas anotaciones (por ejemplo, con TypeDoc para generar docs de API interna).
  - Se documentan también las estructuras de directorios y convenciones en un README para nuevos contribuyentes (por ejemplo, explicar que en `src/modules/` cada módulo sigue una anatomía estándar). Ese README debe actualizarse si la estructura evoluciona.
  - Finalmente, incorporamos elementos de "living documentation" como Storybook para UI (donde cada componente tiene notas que se actualizan cuando cambian propiedades), o Swagger para API, que se regenera con cada despliegue. Esto significa que la documentación siempre refleja la versión actual de la aplicación, no una intención pasada.

- **Sincronización con el control de versiones:** Cada fase concluye con una actualización de documentación, y preferiblemente, documentación y código viajan juntos en el repositorio. Por ejemplo, mantener una carpeta `/docs` en el monorepo con los archivos Markdown de arquitectura, decisiones, etc., versionados junto con el código. Así, si se retrocede a un commit anterior, se puede ver la documentación correspondiente a ese momento. Esto es útil para entender contextos históricos. La documentación viva implica que incluso estos archivos se revisan y corrigen en cada PR relevante.

Adherirnos a estos principios asegura trazabilidad y claridad. En un entorno donde múltiples agentes de IA pueden implementar módulos simultáneamente, la documentación viva es el punto de alineación que previene malentendidos. Cada agente puede consultar la documentación para entender el estado actual del sistema y las normas acordadas, y tras hacer sus contribuciones, debe actualizarla para los siguientes.

## Conclusión

En conclusión, la metodología expuesta proporciona una hoja de ruta estratégica para desarrollar Mateatletas en un entorno modular, asistido por IA, minimizando interferencias. Con fases definidas que se construyen una sobre otra, un enfoque riguroso en testing continuo, la reutilización de componentes/lógica desde el inicio y una documentación que evoluciona con el código, se logra un proceso de desarrollo robusto y escalable. Cada fase tiene objetivos claros, entregables verificables y criterios de cierre, garantizando trazabilidad. Esto permite que diferentes equipos o agentes trabajen en paralelo de forma armoniosa, siempre alineados con la visión arquitectónica global y manteniendo la calidad en cada paso del camino. ¡Al completar estas fases, Mateatletas estará listo para brillar con una base sólida tanto en su tecnología como en sus prácticas de ingeniería!

---

## Referencias

**Documento de diseño Técnico del Backend.pdf**  
file://file_00000000c72061f7ab8686c973faa2af

**Stack Tecnológico y Arquitectura Frontend.pdf**  
file://file_00000000c38461f7b6d52f726989f94b

**How to setup Nest.js & Next.js Mono-Repository? | by Zulfiqar Ali Langah | Medium**  
https://medium.com/@zulfiqar.langah/how-to-setup-nest-js-next-js-mono-repository-8a5d8c3b5849
